---
layout: default
title: Related Works
permalink: /related-works/
---

# Related Works
We used two existing music AI models, the lp-music caps from MAC LAB for auto-captioning, and the music gen from meta for music generation.
## LP-Music Caps
Our system, LPM-Caps, generates captions for music by analyzing short segments of 10 seconds each.

The model is trained using a two-step approach:
	1.	Pretraining on a large-scale pseudo-dataset generated by LLM-based models.
	2.	Transfer learning on a human-annotated music analysis dataset to refine accuracy and quality.

This combination allows LPM-Caps to produce detailed and meaningful descriptions of music clips.

For the demo, we put coffee house wav file into lp-music caps. As you can see, it generates prompts about it.
<video width="640" height="360" controls>
  <source src="img/lpcaps.mov" type="video/mp4">
  Your browser does not support the video tag.
</video>

## Music-gen

The Music Generation model used in this project is a result of Meta’s AudioCraft initiative. AudioCraft provides various models capable of generating music under multiple conditions:
*  Text-conditioned Generation: Generates music based on descriptive text prompts.
*  Music-conditioned Generation: Produces new music inspired by a given music sample.
*  Continual Generation: Generates seamless, continuous musical outputs.

Demo Example

In this project, we provided a Coffee House WAV file as a reference music input.
Additionally, we used the text prompt:
	“I need a new Carol song for this Christmas”
The model successfully generated a fitting carol track inspired by the given input.
<video width="640" height="360" controls>
  <source src="img/musicgen.mov" type="video/mp4">
  Your browser does not support the video tag.
</video>
